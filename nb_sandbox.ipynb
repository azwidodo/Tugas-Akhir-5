{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31eac73fd3732e9fda22e6a2122e160c</td>\n",
       "      <td>['check', 'out', 'other', 'book', 'review', 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4fb438ca422c972b576f4b21772e5f81</td>\n",
       "      <td>['dnf']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>454d50490492ff349e9c44ac941ee082</td>\n",
       "      <td>['book', 'on', 'recommendation', 'shelf', 'sad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173b777cd040cf0d3b9ea5f116a021fe</td>\n",
       "      <td>['good', 'premise', 'but', 'halfway', 'through...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22fe845937341a1a797a7e33beb2b5e2</td>\n",
       "      <td>['horrible', 'book', 'dont', 'know', 'buy', 'm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id  \\\n",
       "0  31eac73fd3732e9fda22e6a2122e160c   \n",
       "1  4fb438ca422c972b576f4b21772e5f81   \n",
       "2  454d50490492ff349e9c44ac941ee082   \n",
       "3  173b777cd040cf0d3b9ea5f116a021fe   \n",
       "4  22fe845937341a1a797a7e33beb2b5e2   \n",
       "\n",
       "                                                text  sentiment  \n",
       "0  ['check', 'out', 'other', 'book', 'review', 'b...          0  \n",
       "1                                            ['dnf']          0  \n",
       "2  ['book', 'on', 'recommendation', 'shelf', 'sad...          0  \n",
       "3  ['good', 'premise', 'but', 'halfway', 'through...          0  \n",
       "4  ['horrible', 'book', 'dont', 'know', 'buy', 'm...          0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data by sentiment\n",
    "\n",
    "def split_sentiment(df):\n",
    "\n",
    "    df_pos = df[df[\"sentiment\"] == 1]\n",
    "    df_neg = df[df[\"sentiment\"] == 0]\n",
    "\n",
    "    return df_pos, df_neg\n",
    "\n",
    "# Split training and testing data\n",
    "\n",
    "def split_data(df_pos, df_neg, random_state=None):\n",
    "\n",
    "    df_train_pos, df_test_pos = train_test_split(df_pos, test_size=0.2, random_state=random_state)\n",
    "    df_train_neg, df_test_neg = train_test_split(df_neg, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    df_train = pd.concat([df_train_pos, df_train_neg])\n",
    "    df_test = pd.concat([df_test_pos, df_test_neg])\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos, df_neg = split_sentiment(df)\n",
    "df_train, df_test = split_data(df_pos, df_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 28586)\n"
     ]
    }
   ],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(df[\"text\"], df[\"sentiment\"], test_size=0.2)\n",
    "\n",
    "cv = CountVectorizer().fit(df_train[\"text\"])\n",
    "\n",
    "x_train_vec = cv.transform(df_train[\"text\"]).toarray()\n",
    "x_test_vec = cv.transform(df_test[\"text\"]).toarray()\n",
    "\n",
    "print(x_train_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df_train[\"sentiment\"])\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "\n",
    "if y.shape[1] == 1:\n",
    "        y = np.concatenate((1 - y, y), axis=1)\n",
    "\n",
    "fc = np.matmul(y.T, x_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4000, 4000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_fc = fc + 1\n",
    "smoothed_cc = smoothed_fc.sum(axis=1)\n",
    "log_probs = np.log(smoothed_fc) - np.log(smoothed_cc.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = np.matmul(x_test_vec, log_probs.T)\n",
    "prediction = np.argmax(posterior, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8575\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(df_test[\"sentiment\"])\n",
    "accuracy = metrics.accuracy_score(y_test, prediction)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.70474809, -0.78845736, -1.29928298, -2.39789527],\n",
       "       [-0.84729786, -1.94591015, -1.94591015, -1.25276297]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = np.array([[2, 5, 3, 1],\n",
    "                [3, 1, 1, 2]])\n",
    "cc = fc.sum(axis=1)\n",
    "cc_2 = cc.reshape(-1, 1)\n",
    "\n",
    "logprobs = np.log(fc) - np.log(cc_2)\n",
    "logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.288996   -5.29873395]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "train = [\"this is sparta yeah\",\n",
    "         \"this this yeah\",\n",
    "         \"is is is sparta\"]\n",
    "\n",
    "test = [\"is sparta yeah yeah no\"]\n",
    "\n",
    "cv = CountVectorizer().fit(train)\n",
    "train_vec = cv.transform(train)\n",
    "test_vec = cv.transform(test)\n",
    "\n",
    "posterior = np.matmul(test_vec.toarray(), logprobs.T)\n",
    "print(posterior)\n",
    "\n",
    "index = np.argmax(posterior)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (ref) Naive Bayes from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sent', 'class']\n",
    "rows = []\n",
    "\n",
    "rows = [['This is my book', 'stmt'], \n",
    "        ['They are novels', 'stmt'],\n",
    "        ['have you read this book', 'question'],\n",
    "        ['who is the author', 'question'],\n",
    "        ['what are the characters', 'question'],\n",
    "        ['This is how I bought the book', 'stmt'],\n",
    "        ['I like fictions', 'stmt'],\n",
    "        ['what is your favorite book', 'question']]\n",
    "\n",
    "dfx = pd.DataFrame(rows, columns=columns)\n",
    "dfx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bow(corpus):\n",
    "    cv = CountVectorizer()\n",
    "\n",
    "    X = cv.fit_transform(corpus)\n",
    "    name_index = dict([(name, index) for index, name in enumerate(cv.get_feature_names_out())])\n",
    "\n",
    "    return X.toarray(), name_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_based_on_class(X, y):\n",
    "    y = np.array(y)\n",
    "    lb = LabelBinarizer()\n",
    "    y = lb.fit_transform(y)\n",
    "\n",
    "    if y.shape[1] == 1:\n",
    "        y = np.concatenate((1 - y, y), axis=1)\n",
    "\n",
    "    # Counts\n",
    "    # y.T shape is (n_classes,n_datapoints) --> X shape is (n_datapoints*n_features)\n",
    "    # Count matrix shape is (n_classes*n_features)\n",
    "    count_matrix = np.matmul(y.T, X)\n",
    "    class_count = y.sum(axis=0)\n",
    "    return count_matrix, y, lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_log_probs(count_matrix, alpha=1):\n",
    "    # adding alpha to the count\n",
    "    smoothed = count_matrix + alpha\n",
    "\n",
    "    # calculate number of words in a given class\n",
    "    denumerator = smoothed.sum(axis=1)\n",
    "\n",
    "    # reshape to 2D column\n",
    "    denumerator = denumerator.reshape(-1, 1)\n",
    "\n",
    "    # log prob = log(num) - log(den)\n",
    "    log_probs = np.log(smoothed) - np.log(denumerator)\n",
    "\n",
    "    return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(query, log_probs, classes):\n",
    "    # calculate posterior probabilities\n",
    "    output = np.matmul(log_probs, query.T)\n",
    "    \n",
    "    # find index using argmax and returns the specified class\n",
    "    index = np.argmax(output)\n",
    "\n",
    "    return classes[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into BOW\n",
    "X, name_index = convert_to_bow(df[\"text\"])\n",
    "\n",
    "# Calculate the counts w.r.t to each class\n",
    "count_matrix, y, classes = count_based_on_class(X, df['sentiment'])\n",
    "\n",
    "# Calculate the log_probabilities\n",
    "log_probabilities = feature_log_probs(count_matrix, alpha = 1)\n",
    "\n",
    "# Using log_probabilities try to predict for a class\n",
    "output = predicting(X[100], log_probabilities, classes)\n",
    "\n",
    "print('Predicted class - ',output)\n",
    "print('Actual class -', df['sentiment'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[\"text\"], df[\"sentiment\"], test_size=0.2, random_state=42)\n",
    "\n",
    "cv = CountVectorizer().fit(x_train)\n",
    "x_train_vec = cv.transform(x_train)\n",
    "x_test_vec = cv.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (actual manual) Naive Bayes from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data by sentiment\n",
    "\n",
    "def split_sentiment(df):\n",
    "\n",
    "    df_pos = df[df[\"sentiment\"] == 1]\n",
    "    df_neg = df[df[\"sentiment\"] == 0]\n",
    "\n",
    "    return df_pos, df_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "\n",
    "def split_data(df_pos, df_neg):\n",
    "\n",
    "    df_train_pos, df_test_pos = train_test_split(df_pos, test_size=0.2)\n",
    "    df_train_neg, df_test_neg = train_test_split(df_neg, test_size=0.2)\n",
    "\n",
    "    df_train = pd.concat([df_train_pos, df_train_neg])\n",
    "    df_test = pd.concat([df_test_pos, df_test_neg])\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocabulary from testing data\n",
    "\n",
    "def get_vocab(df_train):\n",
    "\n",
    "    vocab = []\n",
    "\n",
    "    for i in range(df_train.shape[0]):\n",
    "        list_ = df_train.iloc[i][\"text\"]\n",
    "        list_ = ast.literal_eval(list_)\n",
    "        vocab += list_\n",
    "\n",
    "    vocab_set = set(vocab)\n",
    "\n",
    "    return vocab_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frequency and probability of words in vocab\n",
    "\n",
    "def get_prob(df_train):\n",
    "    vocab = get_vocab(df_train)\n",
    "    V = len(vocab)\n",
    "\n",
    "    pos_words_list = []\n",
    "    neg_words_list = []\n",
    "\n",
    "    df_pos, df_neg = split_sentiment(df_train)\n",
    "\n",
    "    # count all words in each set of data\n",
    "    for i in range(df_pos.shape[0]):\n",
    "        pos_text = df_pos.iloc[i][\"text\"]\n",
    "        pos_text = ast.literal_eval(pos_text)\n",
    "        pos_words_list += pos_text\n",
    "\n",
    "        neg_text = df_neg.iloc[i][\"text\"]\n",
    "        neg_text = ast.literal_eval(neg_text)\n",
    "        neg_words_list += neg_text\n",
    "\n",
    "    pos_words_freq = Counter(pos_words_list)\n",
    "    neg_words_freq = Counter(neg_words_list)\n",
    "\n",
    "    N_pos = sum(pos_words_freq.values())\n",
    "    N_neg = sum(neg_words_freq.values())\n",
    "\n",
    "    # count the probabilities of each word\n",
    "    pos_prob = {}\n",
    "    neg_prob = {}\n",
    "\n",
    "    # use Laplacian smoothing\n",
    "    for i, word in enumerate(vocab):\n",
    "        pos_prob[word] = (pos_words_freq.get(word, 0) + 1) / (N_pos + V)\n",
    "        neg_prob[word] = (neg_words_freq.get(word, 0) + 1) / (N_neg + V)\n",
    "\n",
    "    return pos_prob, neg_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment of text\n",
    "\n",
    "def predict(text, vocab, pos_prob, neg_prob):\n",
    "    score = 0\n",
    "\n",
    "    for word in text:\n",
    "        if word in vocab:\n",
    "            score += math.log(pos_prob[word] / neg_prob[word])\n",
    "\n",
    "    if score > 0:\n",
    "        sentiment = 1\n",
    "    else:\n",
    "        sentiment = 0\n",
    "\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos, df_neg = split_sentiment(df)\n",
    "df_train, df_test = split_data(df_pos, df_neg)\n",
    "\n",
    "vocab = get_vocab(df_train)\n",
    "\n",
    "pos_prob, neg_prob = get_prob(df_train)\n",
    "\n",
    "df_test[\"prediction\"] = df_test[\"text\"].apply(lambda x: predict(x, vocab, pos_prob, neg_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_4 = metrics.accuracy_score(df_test[\"sentiment\"], df_test[\"prediction\"])\n",
    "print(accuracy_4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbdeae21cd698169d80b8f85757407d35b6d9920a79c4c6b4fbd15284371fc7c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('final': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
